/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 * http://www.apache.org/licenses/LICENSE-2.0
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.nifi.processors.network;

import com.fasterxml.jackson.databind.ObjectMapper;
import org.apache.nifi.annotation.behavior.*;
import org.apache.nifi.annotation.behavior.InputRequirement.Requirement;
import org.apache.nifi.annotation.documentation.CapabilityDescription;
import org.apache.nifi.annotation.documentation.Tags;
import org.apache.nifi.annotation.lifecycle.OnScheduled;
import org.apache.nifi.components.AllowableValue;
import org.apache.nifi.components.PropertyDescriptor;
import org.apache.nifi.flowfile.FlowFile;
import org.apache.nifi.logging.ComponentLog;
import org.apache.nifi.processor.AbstractProcessor;
import org.apache.nifi.processor.ProcessContext;
import org.apache.nifi.processor.ProcessSession;
import org.apache.nifi.processor.Relationship;
import org.apache.nifi.processor.exception.ProcessException;
import org.apache.nifi.processors.network.parser.v9.NetflowDataRecord;
import org.apache.nifi.processors.network.parser.v9.NetflowV9ExportPacket;

import java.io.ByteArrayOutputStream;
import java.util.*;

@EventDriven
@SideEffectFree
@SupportsBatching
@InputRequirement(Requirement.INPUT_REQUIRED)
@Tags({ "network", "netflow", "attributes", "datagram", "v9", "packet", "byte" })
@CapabilityDescription("Parses netflowv9 byte ingest and add to NiFi flowfile as attributes or JSON content.")
@ReadsAttributes({ @ReadsAttribute(attribute = "udp.port", description = "Optionally read if packets are received from UDP datagrams.") })
@WritesAttributes({ @WritesAttribute(attribute = "netflowv9.header.*", description = "The key and value generated by the parsing of the header fields."),
        @WritesAttribute(attribute = "netflowv9.record.*", description = "The key and value generated by the parsing of the record fields.") })

public class ParseNetflowV9 extends AbstractProcessor {
    private String destination;
    // Add mapper
    private static final ObjectMapper mapper = new ObjectMapper();

    public static final String FLOWFILE_CONTENT = "flowfile-content";
    public static final String FLOWFILE_ATTRIBUTE = "flowfile-attribute";
    public static final AllowableValue DESTINATION_CONTENT = new AllowableValue(FLOWFILE_CONTENT, FLOWFILE_CONTENT,
            "Parsed data routes as flowfile JSON content");
    public static final AllowableValue DESTINATION_ATTRIBUTES = new AllowableValue(FLOWFILE_ATTRIBUTE, FLOWFILE_ATTRIBUTE,
            "Parsed data routes as flowfile attributes");
    public static final PropertyDescriptor FIELDS_DESTINATION = new PropertyDescriptor.Builder().name("FIELDS_DESTINATION").displayName("Parsed fields destination")
            .description("Indicates whether the results of the parser are written " + "to the FlowFile content or a FlowFile attribute; if using " + DESTINATION_ATTRIBUTES
                    + ", fields will be populated as attributes. If set to " + DESTINATION_CONTENT + ", the netflowv9 field will be converted into a flat JSON object.")
            .required(true).allowableValues(DESTINATION_CONTENT, DESTINATION_ATTRIBUTES).defaultValue(DESTINATION_CONTENT.getDisplayName()).build();

    public static final Relationship REL_FAILURE = new Relationship.Builder().name("failure")
            .description("Any FlowFile that could not be parsed as a netflowv9 message will be transferred to this Relationship without any attributes being added").build();
    public static final Relationship REL_ORIGINAL = new Relationship.Builder().name("original").description("The original raw content").build();
    public static final Relationship REL_SUCCESS = new Relationship.Builder().name("success")
            .description("Any FlowFile that is successfully parsed as a netflowv9 data will be transferred to this Relationship.").build();

    public static final List<PropertyDescriptor> PROPERTIES = Collections.unmodifiableList(Arrays.asList(FIELDS_DESTINATION));
    public static final Set<Relationship> RELATIONSHIPS = Collections.unmodifiableSet(new HashSet<>(Arrays.asList(REL_FAILURE, REL_ORIGINAL, REL_SUCCESS)));

    @Override
    public Set<Relationship> getRelationships() {
        return RELATIONSHIPS;
    }

    @Override
    public final List<PropertyDescriptor> getSupportedPropertyDescriptors() {
        return PROPERTIES;
    }

    @OnScheduled
    public void onScheduled(final ProcessContext context) {
        destination = context.getProperty(FIELDS_DESTINATION).getValue();
    }

    @Override
    public void onTrigger(final ProcessContext context, final ProcessSession session) throws ProcessException {
        final ComponentLog logger = getLogger();
        FlowFile flowFile = session.get();
        if (flowFile == null) {
            return;
        }

        final OptionalInt portNumber = resolvePort(flowFile);
        final ByteArrayOutputStream baos = new ByteArrayOutputStream();
        session.exportTo(flowFile, baos);
        final byte[] buffer = baos.toByteArray();

        final NetflowV9ExportPacket processedRecord;
        try {
            processedRecord = NetflowV9ExportPacket.parse(buffer);
            if(logger.isDebugEnabled()) {
                logger.debug("Parsed {} records from the packet", new Object[] { processedRecord });
            }
        } catch (Throwable e) {
            logger.error("Parser returned unexpected Exception {} while processing {}; routing to failure", new Object[] { e, flowFile });
            session.transfer(flowFile, REL_FAILURE);
            return;
        }

        try {
            final List<FlowFile> multipleRecords = new ArrayList<>();
            switch (destination) {
                case FLOWFILE_ATTRIBUTE:
                    final Map<String, String> attributes = new HashMap<>();
                    generateKV(multipleRecords, session, flowFile, attributes, processedRecord);
                    break;
                case FLOWFILE_CONTENT:
                    // TODO: Implement FLOWFILE_CONTENT
                    //generateJSON(multipleRecords, session, flowFile, parser, processedRecord);
                    break;
            }
            // Create a provenance event recording the routing to success
            multipleRecords.forEach(recordFlowFile -> session.getProvenanceReporter().route(recordFlowFile, REL_SUCCESS));
            session.getProvenanceReporter().route(flowFile, REL_ORIGINAL);
            // Ready to transfer and commit
            session.transfer(flowFile, REL_ORIGINAL);
            session.transfer(multipleRecords, REL_SUCCESS);
            session.adjustCounter("Records Processed", processedRecord.getDataRecords().size(), false);
            session.commit();
        } catch (Exception e) {
            // The flowfile has failed parsing & validation, routing to failure
            logger.error("Failed to parse {} as a netflowv9 message due to {}; routing to failure", new Object[] { flowFile, e });
            // Create a provenance event recording the routing to failure
            session.getProvenanceReporter().route(flowFile, REL_FAILURE);
            session.transfer(flowFile, REL_FAILURE);
            session.commit();
            return;
        } finally {
            session.rollback();
        }
    }

    private void generateKV(final List<FlowFile> multipleRecords, final ProcessSession session, final FlowFile flowFile, final Map<String, String> attributes, final NetflowV9ExportPacket packet) {
        for (NetflowDataRecord dataRecord : packet.getDataRecords()) {
            final Map<String, String> recordAttributes = new HashMap<>(attributes);
            addHeaderAttributes(recordAttributes, packet);

            dataRecord.getData().forEach((type, value) -> {
                recordAttributes.put("netflowv9.record." + type.toString(), String.valueOf(value));
            });

            FlowFile recordFlowFile = session.create(flowFile);
            recordFlowFile = session.putAllAttributes(recordFlowFile, attributes);
            multipleRecords.add(recordFlowFile);
        }
    }

    private OptionalInt resolvePort(final FlowFile flowFile) {
        final String port;
        if ((port = flowFile.getAttribute("udp.port")) != null) {
            return OptionalInt.of(Integer.parseInt(port));
        }
        return OptionalInt.empty();
    }

    private void addHeaderAttributes(final Map<String, String> attributes, final NetflowV9ExportPacket packet) {
        // Process KVs of the Flow Header fields
        packet.getHeader().getKeyValueAttributes().forEach((key, value) -> attributes.put("netflowv9.header." + key, value));
    }
}
